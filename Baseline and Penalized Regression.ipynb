{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implmentation for Baseline Logistic Regression and Penalised Regressions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 1: Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: Import Libraries and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, roc_curve, precision_recall_curve, average_precision_score, f1_score\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, SelectFromModel, RFE\n",
    "import joblib\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from sklearn.base import clone\n",
    "from sklearn.utils import resample\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create a directory for results if it doesn't exist\n",
    "results_dir = f\"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 2: Data Loading and Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Basic Information:\n",
      "Shape of dataset: (30000, 25)\n",
      "\n",
      "First few rows:\n",
      "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
      "0   1    20000.0    2          2         1   24      2      2     -1     -1   \n",
      "1   2   120000.0    2          2         2   26     -1      2      0      0   \n",
      "2   3    90000.0    2          2         2   34      0      0      0      0   \n",
      "3   4    50000.0    2          2         1   37      0      0      0      0   \n",
      "4   5    50000.0    1          2         1   57     -1      0     -1      0   \n",
      "\n",
      "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
      "0  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
      "1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
      "2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
      "3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
      "4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n",
      "\n",
      "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
      "0       0.0       0.0       0.0                           1  \n",
      "1    1000.0       0.0    2000.0                           1  \n",
      "2    1000.0    1000.0    5000.0                           0  \n",
      "3    1100.0    1069.0    1000.0                           0  \n",
      "4    9000.0     689.0     679.0                           0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Missing values in each column:\n",
      "ID                            0\n",
      "LIMIT_BAL                     0\n",
      "SEX                           0\n",
      "EDUCATION                     0\n",
      "MARRIAGE                      0\n",
      "AGE                           0\n",
      "PAY_0                         0\n",
      "PAY_2                         0\n",
      "PAY_3                         0\n",
      "PAY_4                         0\n",
      "PAY_5                         0\n",
      "PAY_6                         0\n",
      "BILL_AMT1                     0\n",
      "BILL_AMT2                     0\n",
      "BILL_AMT3                     0\n",
      "BILL_AMT4                     0\n",
      "BILL_AMT5                     0\n",
      "BILL_AMT6                     0\n",
      "PAY_AMT1                      0\n",
      "PAY_AMT2                      0\n",
      "PAY_AMT3                      0\n",
      "PAY_AMT4                      0\n",
      "PAY_AMT5                      0\n",
      "PAY_AMT6                      0\n",
      "default.payment.next.month    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Section 2: Data Loading and Basic Information\n",
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "credit_data = pd.read_csv(\"UCI_Credit_Card.csv\")\n",
    "\n",
    "# Basic information about the dataset\n",
    "print(\"\\nBasic Information:\")\n",
    "print(f\"Shape of dataset: {credit_data.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(credit_data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(credit_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 3: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Data Preprocessing ====\n",
      "\n",
      "Unique values in EDUCATION: [2 1 3 5 4 6 0]\n",
      "Unique values in MARRIAGE: [1 2 3 0]\n",
      "\n",
      "After cleaning:\n",
      "Unique values in EDUCATION: [2 1 3 4]\n",
      "Unique values in MARRIAGE: [1 2 3]\n",
      "Training set shape: (18000, 23)\n",
      "Validation set shape: (6000, 23)\n",
      "Test set shape: (6000, 23)\n"
     ]
    }
   ],
   "source": [
    "# Section 3: Data Preprocessing\n",
    "print(\"\\n==== Data Preprocessing ====\")\n",
    "\n",
    "# Drop ID column (not useful for modeling)\n",
    "credit_data = credit_data.drop('ID', axis=1)\n",
    "\n",
    "# Check education and marriage for unusual values\n",
    "print(\"\\nUnique values in EDUCATION:\", credit_data['EDUCATION'].unique())\n",
    "print(\"Unique values in MARRIAGE:\", credit_data['MARRIAGE'].unique())\n",
    "\n",
    "# Fix education and marriage variables\n",
    "# For education: 0, 5, 6 are mapped to 4 (Others)\n",
    "# For marriage: 0 is mapped to 3 (Others)\n",
    "credit_data['EDUCATION'] = credit_data['EDUCATION'].map(lambda x: 4 if x in [0, 5, 6] else x)\n",
    "credit_data['MARRIAGE'] = credit_data['MARRIAGE'].map(lambda x: 3 if x == 0 else x)\n",
    "\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(\"Unique values in EDUCATION:\", credit_data['EDUCATION'].unique())\n",
    "print(\"Unique values in MARRIAGE:\", credit_data['MARRIAGE'].unique())\n",
    "\n",
    "# Feature and target variables\n",
    "X = credit_data.drop('default.payment.next.month', axis=1)\n",
    "y = credit_data['default.payment.next.month']\n",
    "\n",
    "# Split data into training, validation and test sets (60%, 20%, 20%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['LIMIT_BAL', 'AGE'] + [col for col in X.columns if col.startswith('BILL_') or col.startswith('PAY_AMT')]\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_val[numerical_cols] = scaler.transform(X_val[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 4: Model Evaluation Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 4: Model Evaluation Function Definition\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val, model_name, selected_features=None):\n",
    "    \"\"\"Evaluate model performance with multiple metrics and visualizations\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Use selected features if provided\n",
    "    X_train_use = X_train[selected_features] if selected_features is not None else X_train\n",
    "    X_val_use = X_val[selected_features] if selected_features is not None else X_val\n",
    "    \n",
    "    # Cross-validation on training data\n",
    "    cv_scores = cross_val_score(model, X_train_use, y_train, cv=cv_strategy, scoring='roc_auc')\n",
    "    \n",
    "    # Fit the model on training data\n",
    "    model.fit(X_train_use, y_train)\n",
    "    \n",
    "    # Predictions on validation data\n",
    "    y_pred_proba = model.predict_proba(X_val_use)[:, 1]\n",
    "    y_pred = model.predict(X_val_use)\n",
    "    \n",
    "    # Compute various metrics\n",
    "    roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "    avg_precision = average_precision_score(y_val, y_pred_proba)\n",
    "    \n",
    "    # Get ROC curve data\n",
    "    fpr, tpr, _ = roc_curve(y_val, y_pred_proba)\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(y_val, y_pred)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    \n",
    "    # Training time\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Training time: {training_time:.2f} seconds\")\n",
    "    print(f\"CV ROC-AUC Scores: {cv_scores}\")\n",
    "    print(f\"Mean CV ROC-AUC: {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")\n",
    "    print(f\"Validation ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Validation Avg Precision: {avg_precision:.4f}\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Plot individual ROC curve\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - {model_name}')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(results_dir, f'roc_curve_{model_name.replace(\" \", \"_\").lower()}.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # For models with coefficients, plot feature importance\n",
    "    if hasattr(model, 'coef_'):\n",
    "        features = selected_features if selected_features is not None else X_train.columns\n",
    "        coef = model.coef_[0]\n",
    "        \n",
    "        # Sort coefficients and feature names\n",
    "        indices = np.argsort(np.abs(coef))\n",
    "        sorted_features = np.array(features)[indices]\n",
    "        sorted_coef = coef[indices]\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.barh(range(len(sorted_coef)), sorted_coef)\n",
    "        plt.yticks(range(len(sorted_coef)), sorted_features)\n",
    "        plt.xlabel('Coefficient magnitude')\n",
    "        plt.title(f'Feature Importance - {model_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, f'feature_importance_{model_name.replace(\" \", \"_\").lower()}.png'))\n",
    "        plt.close()\n",
    "    \n",
    "    # Return key metrics, model, and ROC curve data\n",
    "    return {'avg_precision': avg_precision, 'roc_auc': roc_auc, 'model': model, 'roc_data': (fpr, tpr)}\n",
    "\n",
    "# Dictionary to store models and their performance\n",
    "models = {}\n",
    "\n",
    "# Function to tune hyperparameters\n",
    "def tune_hyperparameters(model, param_grid, X_train, y_train, cv=None, scoring='roc_auc'):\n",
    "    \"\"\"Tune hyperparameters using grid search and cross-validation\"\"\"\n",
    "    if cv is None:\n",
    "        cv = cv_strategy\n",
    "        \n",
    "    grid_search = GridSearchCV(\n",
    "        model, param_grid, cv=cv, scoring=scoring, n_jobs=-1, verbose=1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 5: Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Model Building and Evaluation ====\n",
      "\n",
      "Training baseline Logistic Regression...\n",
      "\n",
      "Baseline Logistic Regression Results:\n",
      "Training time: 0.59 seconds\n",
      "CV ROC-AUC Scores: [0.74433195 0.72314923 0.71371748 0.71553735 0.7286708 ]\n",
      "Mean CV ROC-AUC: 0.7251 (±0.0110)\n",
      "Validation ROC-AUC: 0.7030\n",
      "Validation Avg Precision: 0.4785\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88      4673\n",
      "           1       0.66      0.23      0.34      1327\n",
      "\n",
      "    accuracy                           0.80      6000\n",
      "   macro avg       0.74      0.60      0.61      6000\n",
      "weighted avg       0.78      0.80      0.76      6000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4519  154]\n",
      " [1027  300]]\n"
     ]
    }
   ],
   "source": [
    "# Section 5: Baseline Model\n",
    "print(\"\\n==== Model Building and Evaluation ====\")\n",
    "\n",
    "# Baseline Logistic Regression\n",
    "print(\"\\nTraining baseline Logistic Regression...\")\n",
    "baseline_model = LogisticRegression(random_state=42, max_iter=2000)\n",
    "models = {}\n",
    "models['Baseline Logistic Regression'] = evaluate_model(baseline_model, X_train, y_train, X_val, y_val, \"Baseline Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 6: Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Ridge Logistic Regression with Hyperparameter Tuning...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters: {'C': 1.0, 'class_weight': {0: 1, 1: 4}}\n",
      "Best CV score: 0.7256\n",
      "\n",
      "Ridge Logistic Regression (Tuned) Results:\n",
      "Training time: 1.06 seconds\n",
      "CV ROC-AUC Scores: [0.74539244 0.72341177 0.71468433 0.71497468 0.72933821]\n",
      "Mean CV ROC-AUC: 0.7256 (±0.0113)\n",
      "Validation ROC-AUC: 0.7034\n",
      "Validation Avg Precision: 0.4757\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.60      0.71      4673\n",
      "           1       0.32      0.67      0.44      1327\n",
      "\n",
      "    accuracy                           0.62      6000\n",
      "   macro avg       0.59      0.64      0.57      6000\n",
      "weighted avg       0.75      0.62      0.65      6000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2815 1858]\n",
      " [ 437  890]]\n"
     ]
    }
   ],
   "source": [
    "# Section 6: Ridge Regression\n",
    "# Ridge Logistic Regression (L2 regularization) with hyperparameter tuning\n",
    "print(\"\\nTraining Ridge Logistic Regression with Hyperparameter Tuning...\")\n",
    "ridge_param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "    'class_weight': [None, 'balanced', {0: 1, 1: 3}, {0: 1, 1: 4}]\n",
    "}\n",
    "ridge_base = LogisticRegression(penalty='l2', random_state=42, max_iter=2000)\n",
    "ridge_tuned = tune_hyperparameters(ridge_base, ridge_param_grid, X_train, y_train)\n",
    "models['Ridge Logistic Regression (Tuned)'] = evaluate_model(ridge_tuned, X_train, y_train, X_val, y_val, \"Ridge Logistic Regression (Tuned)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 7: Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Lasso Logistic Regression with Hyperparameter Tuning...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters: {'C': 1.0, 'class_weight': {0: 1, 1: 4}}\n",
      "Best CV score: 0.7256\n",
      "\n",
      "Lasso Logistic Regression (Tuned) Results:\n",
      "Training time: 1.69 seconds\n",
      "CV ROC-AUC Scores: [0.74537721 0.72345344 0.71462385 0.71501094 0.72941744]\n",
      "Mean CV ROC-AUC: 0.7256 (±0.0113)\n",
      "Validation ROC-AUC: 0.7034\n",
      "Validation Avg Precision: 0.4757\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.60      0.71      4673\n",
      "           1       0.32      0.67      0.44      1327\n",
      "\n",
      "    accuracy                           0.62      6000\n",
      "   macro avg       0.60      0.64      0.57      6000\n",
      "weighted avg       0.75      0.62      0.65      6000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2815 1858]\n",
      " [ 436  891]]\n"
     ]
    }
   ],
   "source": [
    "# Section 7: Lasso Regression\n",
    "# Lasso Logistic Regression (L1 regularization) with hyperparameter tuning\n",
    "print(\"\\nTraining Lasso Logistic Regression with Hyperparameter Tuning...\")\n",
    "lasso_param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "    'class_weight': [None, 'balanced', {0: 1, 1: 3}, {0: 1, 1: 4}]\n",
    "}\n",
    "lasso_base = LogisticRegression(penalty='l1', solver='liblinear', random_state=42, max_iter=2000)\n",
    "lasso_tuned = tune_hyperparameters(lasso_base, lasso_param_grid, X_train, y_train)\n",
    "models['Lasso Logistic Regression (Tuned)'] = evaluate_model(lasso_tuned, X_train, y_train, X_val, y_val, \"Lasso Logistic Regression (Tuned)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 8: Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Elastic Net Logistic Regression with Hyperparameter Tuning...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best parameters: {'C': 1.0, 'class_weight': {0: 1, 1: 4}, 'l1_ratio': 0.8}\n",
      "Best CV score: 0.7256\n",
      "\n",
      "Elastic Net Logistic Regression (Tuned) Results:\n",
      "Training time: 5.05 seconds\n",
      "CV ROC-AUC Scores: [0.74538572 0.72344448 0.71462385 0.71499079 0.72940625]\n",
      "Mean CV ROC-AUC: 0.7256 (±0.0113)\n",
      "Validation ROC-AUC: 0.7034\n",
      "Validation Avg Precision: 0.4757\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.60      0.71      4673\n",
      "           1       0.32      0.67      0.44      1327\n",
      "\n",
      "    accuracy                           0.62      6000\n",
      "   macro avg       0.59      0.64      0.57      6000\n",
      "weighted avg       0.75      0.62      0.65      6000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2812 1861]\n",
      " [ 436  891]]\n"
     ]
    }
   ],
   "source": [
    "# Section 8: Elastic Net\n",
    "# Elastic Net Logistic Regression with hyperparameter tuning\n",
    "print(\"\\nTraining Elastic Net Logistic Regression with Hyperparameter Tuning...\")\n",
    "elastic_net_param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1.0],\n",
    "    'l1_ratio': [0.2, 0.5, 0.8],\n",
    "    'class_weight': [None, 'balanced', {0: 1, 1: 3}, {0: 1, 1: 4}]\n",
    "}\n",
    "elastic_net_base = LogisticRegression(penalty='elasticnet', solver='saga', random_state=42, max_iter=2000)\n",
    "elastic_net_tuned = tune_hyperparameters(elastic_net_base, elastic_net_param_grid, X_train, y_train)\n",
    "models['Elastic Net Logistic Regression (Tuned)'] = evaluate_model(elastic_net_tuned, X_train, y_train, X_val, y_val, \"Elastic Net Logistic Regression (Tuned)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 9: Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Forward Selection with different class weights...\n",
      "\n",
      "Trying Forward Selection with class_weight: None\n",
      "Selected features (Forward): ['LIMIT_BAL', 'SEX', 'PAY_0', 'PAY_3', 'PAY_4', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
      "\n",
      "Forward Selection (weight=None) Results:\n",
      "Training time: 0.24 seconds\n",
      "CV ROC-AUC Scores: [0.74172888 0.72705293 0.71696639 0.7183234  0.73335322]\n",
      "Mean CV ROC-AUC: 0.7275 (±0.0093)\n",
      "Validation ROC-AUC: 0.7071\n",
      "Validation Avg Precision: 0.4791\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89      4673\n",
      "           1       0.68      0.23      0.34      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.75      0.60      0.61      6000\n",
      "weighted avg       0.79      0.81      0.77      6000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4532  141]\n",
      " [1024  303]]\n",
      "\n",
      "Trying Forward Selection with class_weight: balanced\n",
      "Selected features (Forward): ['LIMIT_BAL', 'SEX', 'PAY_0', 'PAY_3', 'PAY_4', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
      "\n",
      "Forward Selection (weight=balanced) Results:\n",
      "Training time: 0.18 seconds\n",
      "CV ROC-AUC Scores: [0.7421227  0.72714836 0.71687185 0.71812465 0.73319208]\n",
      "Mean CV ROC-AUC: 0.7275 (±0.0095)\n",
      "Validation ROC-AUC: 0.7070\n",
      "Validation Avg Precision: 0.4782\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77      4673\n",
      "           1       0.37      0.64      0.47      1327\n",
      "\n",
      "    accuracy                           0.68      6000\n",
      "   macro avg       0.62      0.66      0.62      6000\n",
      "weighted avg       0.76      0.68      0.70      6000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3214 1459]\n",
      " [ 481  846]]\n",
      "\n",
      "Trying Forward Selection with class_weight: {0: 1, 1: 3}\n",
      "Selected features (Forward): ['LIMIT_BAL', 'SEX', 'PAY_0', 'PAY_3', 'PAY_4', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
      "\n",
      "Forward Selection (weight={0: 1, 1: 3}) Results:\n",
      "Training time: 0.17 seconds\n",
      "CV ROC-AUC Scores: [0.74214869 0.72712775 0.71686782 0.71803781 0.73327131]\n",
      "Mean CV ROC-AUC: 0.7275 (±0.0095)\n",
      "Validation ROC-AUC: 0.7070\n",
      "Validation Avg Precision: 0.4784\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85      4673\n",
      "           1       0.48      0.51      0.50      1327\n",
      "\n",
      "    accuracy                           0.77      6000\n",
      "   macro avg       0.67      0.68      0.67      6000\n",
      "weighted avg       0.78      0.77      0.77      6000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3950  723]\n",
      " [ 648  679]]\n",
      "\n",
      "Trying Forward Selection with class_weight: {0: 1, 1: 4}\n",
      "Selected features (Forward): ['LIMIT_BAL', 'SEX', 'PAY_0', 'PAY_3', 'PAY_4', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
      "\n",
      "Forward Selection (weight={0: 1, 1: 4}) Results:\n",
      "Training time: 0.16 seconds\n",
      "CV ROC-AUC Scores: [0.74216885 0.72716762 0.71688126 0.71812644 0.73316074]\n",
      "Mean CV ROC-AUC: 0.7275 (±0.0095)\n",
      "Validation ROC-AUC: 0.7069\n",
      "Validation Avg Precision: 0.4782\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.54      0.67      4673\n",
      "           1       0.31      0.71      0.43      1327\n",
      "\n",
      "    accuracy                           0.58      6000\n",
      "   macro avg       0.59      0.63      0.55      6000\n",
      "weighted avg       0.74      0.58      0.62      6000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2543 2130]\n",
      " [ 383  944]]\n",
      "\n",
      "Best Forward Selection class weight: None with ROC-AUC: 0.7071\n"
     ]
    }
   ],
   "source": [
    "# Section 9: Forward Selection\n",
    "# Forward Selection with different class weights\n",
    "print(\"\\nTraining Forward Selection with different class weights...\")\n",
    "class_weights = [None, 'balanced', {0: 1, 1: 3}, {0: 1, 1: 4}]\n",
    "best_forward_auc = 0\n",
    "best_forward_model = None\n",
    "best_forward_weight = None\n",
    "\n",
    "for weight in class_weights:\n",
    "    print(f\"\\nTrying Forward Selection with class_weight: {weight}\")\n",
    "    forward_selector = SequentialFeatureSelector(\n",
    "        LogisticRegression(random_state=42, max_iter=2000, class_weight=weight),\n",
    "        n_features_to_select=10,\n",
    "        direction='forward',\n",
    "        scoring='roc_auc',\n",
    "        cv=3\n",
    "    )\n",
    "    forward_selector.fit(X_train, y_train)\n",
    "    forward_features = X_train.columns[forward_selector.get_support()]\n",
    "    print(f\"Selected features (Forward): {forward_features.tolist()}\")\n",
    "    \n",
    "    # Train model with selected features\n",
    "    forward_model = LogisticRegression(random_state=42, max_iter=2000, class_weight=weight)\n",
    "    results = evaluate_model(forward_model, X_train, y_train, X_val, y_val, f\"Forward Selection (weight={weight})\", forward_features)\n",
    "    \n",
    "    if results['roc_auc'] > best_forward_auc:\n",
    "        best_forward_auc = results['roc_auc']\n",
    "        best_forward_model = forward_model\n",
    "        best_forward_weight = weight\n",
    "        best_forward_features = forward_features\n",
    "\n",
    "models['Forward Selection'] = {'model': best_forward_model, 'roc_auc': best_forward_auc, 'features': best_forward_features}\n",
    "print(f\"\\nBest Forward Selection class weight: {best_forward_weight} with ROC-AUC: {best_forward_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 10: Backward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Backward Selection with different class weights...\n",
      "\n",
      "Trying Backward Selection with class_weight: None\n",
      "Dropped feature 'BILL_AMT6' (t-stat: 0.0019)\n",
      "Dropped feature 'BILL_AMT2' (t-stat: 0.0397)\n",
      "Dropped feature 'PAY_AMT5' (t-stat: 0.1437)\n",
      "Dropped feature 'BILL_AMT5' (t-stat: 0.2366)\n",
      "Dropped feature 'PAY_5' (t-stat: 0.3839)\n",
      "Dropped feature 'PAY_AMT3' (t-stat: 0.6287)\n",
      "Dropped feature 'BILL_AMT4' (t-stat: 0.2367)\n",
      "Dropped feature 'PAY_AMT4' (t-stat: 0.9549)\n",
      "Dropped feature 'PAY_AMT6' (t-stat: 1.1021)\n",
      "Dropped feature 'PAY_6' (t-stat: 1.5420)\n",
      "Dropped feature 'BILL_AMT3' (t-stat: 1.9808)\n",
      "Dropped feature 'PAY_AMT1' (t-stat: 2.0973)\n",
      "Dropped feature 'PAY_3' (t-stat: 1.8506)\n",
      "Dropped feature 'AGE' (t-stat: 2.3994)\n",
      "Dropped feature 'SEX' (t-stat: 3.1665)\n",
      "Dropped feature 'PAY_AMT2' (t-stat: 2.6110)\n",
      "Dropped feature 'EDUCATION' (t-stat: 3.7277)\n",
      "Dropped feature 'PAY_2' (t-stat: 4.7961)\n",
      "Dropped feature 'MARRIAGE' (t-stat: 4.9659)\n",
      "Dropped feature 'BILL_AMT1' (t-stat: 5.5906)\n",
      "Dropped feature 'PAY_4' (t-stat: 7.0784)\n",
      "Dropped feature 'LIMIT_BAL' (t-stat: 10.5446)\n",
      "\n",
      "Best model for this weight has 13 features:\n",
      "Selected features: ['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'BILL_AMT1', 'BILL_AMT3', 'PAY_AMT1', 'PAY_AMT2']\n",
      "Mean CV ROC-AUC: 0.7267 (±0.0105)\n",
      "\n",
      "Backward Selection (weight=None) Results:\n",
      "Training time: 0.57 seconds\n",
      "CV ROC-AUC Scores: [0.74485211 0.72508427 0.71677508 0.71654989 0.73024645]\n",
      "Mean CV ROC-AUC: 0.7267 (±0.0105)\n",
      "Validation ROC-AUC: 0.7030\n",
      "Validation Avg Precision: 0.4761\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88      4673\n",
      "           1       0.65      0.23      0.33      1327\n",
      "\n",
      "    accuracy                           0.80      6000\n",
      "   macro avg       0.73      0.60      0.61      6000\n",
      "weighted avg       0.78      0.80      0.76      6000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4512  161]\n",
      " [1028  299]]\n",
      "\n",
      "Trying Backward Selection with class_weight: balanced\n",
      "Dropped feature 'PAY_AMT5' (t-stat: 0.0466)\n",
      "Dropped feature 'PAY_5' (t-stat: 0.0685)\n",
      "Dropped feature 'BILL_AMT2' (t-stat: 0.0732)\n",
      "Dropped feature 'BILL_AMT5' (t-stat: 0.1988)\n",
      "Dropped feature 'BILL_AMT6' (t-stat: 0.2055)\n",
      "Dropped feature 'BILL_AMT4' (t-stat: 0.5173)\n",
      "Dropped feature 'PAY_AMT3' (t-stat: 0.4475)\n",
      "Dropped feature 'PAY_6' (t-stat: 0.6868)\n",
      "Dropped feature 'PAY_AMT4' (t-stat: 0.7863)\n",
      "Dropped feature 'PAY_AMT6' (t-stat: 0.9786)\n",
      "Dropped feature 'BILL_AMT3' (t-stat: 1.5742)\n",
      "Dropped feature 'AGE' (t-stat: 2.3291)\n",
      "Dropped feature 'PAY_3' (t-stat: 2.2326)\n",
      "Dropped feature 'PAY_AMT1' (t-stat: 1.8883)\n",
      "Dropped feature 'PAY_AMT2' (t-stat: 3.0664)\n",
      "Dropped feature 'PAY_4' (t-stat: 3.4254)\n",
      "Dropped feature 'SEX' (t-stat: 3.4957)\n",
      "Dropped feature 'EDUCATION' (t-stat: 4.2035)\n",
      "Dropped feature 'MARRIAGE' (t-stat: 4.6798)\n",
      "Dropped feature 'LIMIT_BAL' (t-stat: 5.2492)\n",
      "Dropped feature 'BILL_AMT1' (t-stat: 9.5294)\n",
      "Dropped feature 'PAY_2' (t-stat: 9.3226)\n",
      "\n",
      "Best model for this weight has 14 features:\n",
      "Selected features: ['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'BILL_AMT1', 'BILL_AMT3', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT6']\n",
      "Mean CV ROC-AUC: 0.7269 (±0.0107)\n",
      "\n",
      "Backward Selection (weight=balanced) Results:\n",
      "Training time: 1.23 seconds\n",
      "CV ROC-AUC Scores: [0.74557748 0.72484055 0.71687275 0.71648632 0.7305965 ]\n",
      "Mean CV ROC-AUC: 0.7269 (±0.0107)\n",
      "Validation ROC-AUC: 0.7034\n",
      "Validation Avg Precision: 0.4752\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.71      0.78      4673\n",
      "           1       0.38      0.61      0.46      1327\n",
      "\n",
      "    accuracy                           0.69      6000\n",
      "   macro avg       0.62      0.66      0.62      6000\n",
      "weighted avg       0.76      0.69      0.71      6000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3341 1332]\n",
      " [ 522  805]]\n",
      "\n",
      "Trying Backward Selection with class_weight: {0: 1, 1: 3}\n",
      "Dropped feature 'PAY_AMT5' (t-stat: 0.0153)\n",
      "Dropped feature 'PAY_5' (t-stat: 0.0112)\n",
      "Dropped feature 'BILL_AMT2' (t-stat: 0.0687)\n",
      "Dropped feature 'BILL_AMT5' (t-stat: 0.2542)\n",
      "Dropped feature 'BILL_AMT6' (t-stat: 0.1601)\n",
      "Dropped feature 'BILL_AMT4' (t-stat: 0.5219)\n",
      "Dropped feature 'PAY_AMT3' (t-stat: 0.5141)\n",
      "Dropped feature 'PAY_6' (t-stat: 0.8088)\n",
      "Dropped feature 'PAY_AMT4' (t-stat: 0.8225)\n",
      "Dropped feature 'PAY_AMT6' (t-stat: 0.8924)\n",
      "Dropped feature 'BILL_AMT3' (t-stat: 1.7346)\n",
      "Dropped feature 'PAY_AMT1' (t-stat: 2.2377)\n",
      "Dropped feature 'PAY_3' (t-stat: 1.8901)\n",
      "Dropped feature 'AGE' (t-stat: 2.7945)\n",
      "Dropped feature 'PAY_AMT2' (t-stat: 2.6491)\n",
      "Dropped feature 'SEX' (t-stat: 3.0052)\n",
      "Dropped feature 'PAY_4' (t-stat: 4.5383)\n",
      "Dropped feature 'EDUCATION' (t-stat: 4.3555)\n",
      "Dropped feature 'MARRIAGE' (t-stat: 4.8302)\n",
      "Dropped feature 'LIMIT_BAL' (t-stat: 5.1234)\n",
      "Dropped feature 'PAY_2' (t-stat: 10.4378)\n",
      "Dropped feature 'BILL_AMT1' (t-stat: 10.3264)\n",
      "\n",
      "Best model for this weight has 14 features:\n",
      "Selected features: ['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'BILL_AMT1', 'BILL_AMT3', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT6']\n",
      "Mean CV ROC-AUC: 0.7269 (±0.0107)\n",
      "\n",
      "Backward Selection (weight={0: 1, 1: 3}) Results:\n",
      "Training time: 0.36 seconds\n",
      "CV ROC-AUC Scores: [0.74552282 0.7248634  0.71679568 0.71650781 0.73062112]\n",
      "Mean CV ROC-AUC: 0.7269 (±0.0107)\n",
      "Validation ROC-AUC: 0.7034\n",
      "Validation Avg Precision: 0.4754\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84      4673\n",
      "           1       0.47      0.53      0.50      1327\n",
      "\n",
      "    accuracy                           0.76      6000\n",
      "   macro avg       0.66      0.68      0.67      6000\n",
      "weighted avg       0.77      0.76      0.77      6000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3875  798]\n",
      " [ 626  701]]\n",
      "\n",
      "Trying Backward Selection with class_weight: {0: 1, 1: 4}\n",
      "Dropped feature 'PAY_AMT5' (t-stat: 0.0682)\n",
      "Dropped feature 'BILL_AMT2' (t-stat: 0.0770)\n",
      "Dropped feature 'PAY_5' (t-stat: 0.0979)\n",
      "Dropped feature 'BILL_AMT5' (t-stat: 0.2024)\n",
      "Dropped feature 'BILL_AMT6' (t-stat: 0.2341)\n",
      "Dropped feature 'BILL_AMT4' (t-stat: 0.4842)\n",
      "Dropped feature 'PAY_6' (t-stat: 0.5873)\n",
      "Dropped feature 'PAY_AMT3' (t-stat: 0.4351)\n",
      "Dropped feature 'PAY_AMT4' (t-stat: 0.7582)\n",
      "Dropped feature 'PAY_AMT6' (t-stat: 0.8657)\n",
      "Dropped feature 'BILL_AMT3' (t-stat: 1.4283)\n",
      "Dropped feature 'PAY_AMT1' (t-stat: 2.0480)\n",
      "Dropped feature 'PAY_3' (t-stat: 1.8200)\n",
      "Dropped feature 'PAY_AMT2' (t-stat: 2.5171)\n",
      "Dropped feature 'AGE' (t-stat: 2.4157)\n",
      "Dropped feature 'SEX' (t-stat: 3.5866)\n",
      "Dropped feature 'EDUCATION' (t-stat: 3.8080)\n",
      "Dropped feature 'PAY_4' (t-stat: 4.0792)\n",
      "Dropped feature 'LIMIT_BAL' (t-stat: 4.8208)\n",
      "Dropped feature 'MARRIAGE' (t-stat: 4.1935)\n",
      "Dropped feature 'PAY_2' (t-stat: 11.3716)\n",
      "Dropped feature 'BILL_AMT1' (t-stat: 8.8466)\n",
      "\n",
      "Best model for this weight has 14 features:\n",
      "Selected features: ['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'BILL_AMT1', 'BILL_AMT3', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT6']\n",
      "Mean CV ROC-AUC: 0.7269 (±0.0107)\n",
      "\n",
      "Backward Selection (weight={0: 1, 1: 4}) Results:\n",
      "Training time: 0.34 seconds\n",
      "CV ROC-AUC Scores: [0.74563527 0.72481859 0.71693592 0.71651721 0.73057412]\n",
      "Mean CV ROC-AUC: 0.7269 (±0.0107)\n",
      "Validation ROC-AUC: 0.7034\n",
      "Validation Avg Precision: 0.4751\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.60      0.71      4673\n",
      "           1       0.32      0.67      0.44      1327\n",
      "\n",
      "    accuracy                           0.62      6000\n",
      "   macro avg       0.60      0.64      0.57      6000\n",
      "weighted avg       0.75      0.62      0.65      6000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2814 1859]\n",
      " [ 434  893]]\n",
      "\n",
      "Best Backward Selection class weight: balanced with ROC-AUC: 0.7034\n"
     ]
    }
   ],
   "source": [
    "# Section 10: Backward Selection\n",
    "# Backward Selection with different class weights\n",
    "print(\"\\nTraining Backward Selection with different class weights...\")\n",
    "class_weights = [None, 'balanced', {0: 1, 1: 3}, {0: 1, 1: 4}]\n",
    "best_backward_auc = 0\n",
    "best_backward_model = None\n",
    "best_backward_weight = None\n",
    "\n",
    "for weight in class_weights:\n",
    "    print(f\"\\nTrying Backward Selection with class_weight: {weight}\")\n",
    "    \n",
    "    # Initialize variables to store models and their metrics\n",
    "    models_by_k = {}\n",
    "    features_remaining = X_train.columns.tolist()\n",
    "    n_features = len(features_remaining)\n",
    "    \n",
    "    # For each k from p down to 1\n",
    "    for k in range(n_features, 0, -1):\n",
    "        # Fit model with current features\n",
    "        model = LogisticRegression(random_state=42, max_iter=2000, class_weight=weight)\n",
    "        model.fit(X_train[features_remaining], y_train)\n",
    "        \n",
    "        # Calculate t-statistics for each feature\n",
    "        y_pred = model.predict(X_train[features_remaining])\n",
    "        residuals = y_train - y_pred\n",
    "        \n",
    "        # Calculate standard errors using bootstrap\n",
    "        n_bootstrap = 100\n",
    "        coef_samples = np.zeros((n_bootstrap, len(features_remaining)))\n",
    "        \n",
    "        for i in range(n_bootstrap):\n",
    "            # Bootstrap sample indices\n",
    "            indices = np.random.choice(len(y_train), len(y_train), replace=True)\n",
    "            # Fit model on bootstrap sample\n",
    "            model_boot = LogisticRegression(random_state=42, max_iter=2000, class_weight=weight)\n",
    "            model_boot.fit(X_train[features_remaining].iloc[indices], y_train.iloc[indices])\n",
    "            coef_samples[i, :] = model_boot.coef_[0]\n",
    "        \n",
    "        # Calculate standard errors\n",
    "        std_errors = np.std(coef_samples, axis=0)\n",
    "        t_stats = np.abs(model.coef_[0] / std_errors)\n",
    "        \n",
    "        # Store current model and its cross-validated metrics\n",
    "        cv_scores = cross_val_score(model, X_train[features_remaining], y_train, \n",
    "                                  cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "                                  scoring='roc_auc')\n",
    "        \n",
    "        models_by_k[k] = {\n",
    "            'features': features_remaining.copy(),\n",
    "            'model': clone(model),\n",
    "            'cv_roc_auc_mean': cv_scores.mean(),\n",
    "            'cv_roc_auc_std': cv_scores.std()\n",
    "        }\n",
    "        \n",
    "        # If we need to remove more features\n",
    "        if k > 1:\n",
    "            # Find feature with smallest absolute t-statistic\n",
    "            min_t_idx = np.argmin(t_stats)\n",
    "            # Remove that feature\n",
    "            removed_feature = features_remaining.pop(min_t_idx)\n",
    "            print(f\"Dropped feature '{removed_feature}' (t-stat: {t_stats[min_t_idx]:.4f})\")\n",
    "    \n",
    "    # Select best model using cross-validated ROC-AUC\n",
    "    best_k = max(models_by_k.keys(), key=lambda k: models_by_k[k]['cv_roc_auc_mean'])\n",
    "    best_model = models_by_k[best_k]['model']\n",
    "    selected_features = models_by_k[best_k]['features']\n",
    "    \n",
    "    print(f\"\\nBest model for this weight has {best_k} features:\")\n",
    "    print(f\"Selected features: {selected_features}\")\n",
    "    print(f\"Mean CV ROC-AUC: {models_by_k[best_k]['cv_roc_auc_mean']:.4f} (±{models_by_k[best_k]['cv_roc_auc_std']:.4f})\")\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    results = evaluate_model(best_model, X_train, y_train, X_val, y_val, \n",
    "                           f\"Backward Selection (weight={weight})\", selected_features)\n",
    "    \n",
    "    if results['roc_auc'] > best_backward_auc:\n",
    "        best_backward_auc = results['roc_auc']\n",
    "        best_backward_model = best_model\n",
    "        best_backward_weight = weight\n",
    "        best_backward_features = selected_features\n",
    "\n",
    "models['Backward Selection'] = {'model': best_backward_model, 'roc_auc': best_backward_auc, 'features': best_backward_features}\n",
    "print(f\"\\nBest Backward Selection class weight: {best_backward_weight} with ROC-AUC: {best_backward_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 11: Model Comparison and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Creating Combined ROC Curve Plot ====\n",
      "\n",
      "==== Model Comparison for Best Models ====\n",
      "\n",
      "Models ranked by ROC-AUC performance:\n",
      "1. Forward Selection (no weights): ROC-AUC = 0.7071, Avg Precision = 0.4791\n",
      "2. Lasso (w={0: 1, 1: 4}): ROC-AUC = 0.7034, Avg Precision = 0.4757\n",
      "3. Elastic Net (w={0: 1, 1: 4}): ROC-AUC = 0.7034, Avg Precision = 0.4757\n",
      "4. Backward Selection (w={0: 1, 1: 3}): ROC-AUC = 0.7034, Avg Precision = 0.4752\n",
      "5. Ridge (w={0: 1, 1: 4}): ROC-AUC = 0.7034, Avg Precision = 0.4757\n",
      "6. Baseline LR: ROC-AUC = 0.7030, Avg Precision = 0.4785\n",
      "\n",
      "==== Best Model: Forward Selection (no weights) with ROC-AUC 0.7071 ====\n"
     ]
    }
   ],
   "source": [
    "# Section 11: Model Comparison and Visualization\n",
    "print(\"\\n==== Creating Combined ROC Curve Plot ====\")\n",
    "plt.figure(figsize=(12, 10))\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown']\n",
    "\n",
    "# Store best models and their metrics for comparison\n",
    "best_models = {\n",
    "    'Baseline LR': baseline_model,\n",
    "    'Ridge (w={0: 1, 1: 4})': ridge_tuned,\n",
    "    'Lasso (w={0: 1, 1: 4})': lasso_tuned,\n",
    "    'Elastic Net (w={0: 1, 1: 4})': elastic_net_tuned,\n",
    "    'Forward Selection (no weights)': best_forward_model,\n",
    "    'Backward Selection (w={0: 1, 1: 3})': best_backward_model\n",
    "}\n",
    "\n",
    "# Plot ROC curves for best models\n",
    "for (model_name, model), color in zip(best_models.items(), colors):\n",
    "    if model_name.startswith('Forward Selection'):\n",
    "        y_pred_proba = model.predict_proba(X_val[best_forward_features])[:, 1]\n",
    "    elif model_name.startswith('Backward Selection'):\n",
    "        y_pred_proba = model.predict_proba(X_val[best_backward_features])[:, 1]\n",
    "    else:\n",
    "        y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_val, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, color=color, label=f'{model_name} (AUC = {roc_auc:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Combined ROC Curves for Best Models')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, 'combined_roc_curves_best_models.png'), bbox_inches='tight', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Create comparison chart for best models\n",
    "print(\"\\n==== Model Comparison for Best Models ====\")\n",
    "model_metrics = []\n",
    "\n",
    "for model_name, model in best_models.items():\n",
    "    if model_name.startswith('Forward Selection'):\n",
    "        y_pred_proba = model.predict_proba(X_val[best_forward_features])[:, 1]\n",
    "    elif model_name.startswith('Backward Selection'):\n",
    "        y_pred_proba = model.predict_proba(X_val[best_backward_features])[:, 1]\n",
    "    else:\n",
    "        y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "    avg_precision = average_precision_score(y_val, y_pred_proba)\n",
    "    model_metrics.append({\n",
    "        'Model': model_name,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'Avg Precision': avg_precision\n",
    "    })\n",
    "\n",
    "# Sort models by ROC-AUC performance\n",
    "model_metrics = sorted(model_metrics, key=lambda x: x['ROC-AUC'], reverse=True)\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\nModels ranked by ROC-AUC performance:\")\n",
    "for i, metrics in enumerate(model_metrics, 1):\n",
    "    print(f\"{i}. {metrics['Model']}: ROC-AUC = {metrics['ROC-AUC']:.4f}, Avg Precision = {metrics['Avg Precision']:.4f}\")\n",
    "\n",
    "# Create bar plot comparing models\n",
    "plt.figure(figsize=(14, 8))\n",
    "models_names = [m['Model'] for m in model_metrics]\n",
    "roc_auc_scores = [m['ROC-AUC'] for m in model_metrics]\n",
    "\n",
    "bars = plt.bar(models_names, roc_auc_scores)\n",
    "plt.title('Model Comparison - ROC-AUC Scores (Best Models)')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('ROC-AUC Score')\n",
    "plt.ylim(0.702, 0.708)  # Adjusted y-axis limits to zoom in on the differences\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "bars[0].set_color('red')  # Highlight the best model\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Added more visible grid\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, 'model_comparison_best_models.png'))\n",
    "plt.close()\n",
    "\n",
    "# Find the overall best model\n",
    "best_model_metrics = max(model_metrics, key=lambda x: x['ROC-AUC'])\n",
    "best_model_name = best_model_metrics['Model']\n",
    "best_auc = best_model_metrics['ROC-AUC']\n",
    "\n",
    "print(f\"\\n==== Best Model: {best_model_name} with ROC-AUC {best_auc:.4f} ====\")\n",
    "\n",
    "def find_optimal_threshold(y_true, y_pred_proba):\n",
    "    \"\"\"Find the probability threshold that maximizes F1 score\"\"\"\n",
    "    thresholds = np.arange(0.1, 1.0, 0.01)\n",
    "    f1_scores = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "    max_f1 = max(f1_scores)\n",
    "    \n",
    "    # Plot F1 scores vs thresholds\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(thresholds, f1_scores)\n",
    "    plt.axvline(x=optimal_threshold, color='r', linestyle='--', \n",
    "                label=f'Optimal threshold = {optimal_threshold:.2f}')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('F1 Score vs Classification Threshold')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(results_dir, 'f1_vs_threshold.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    return optimal_threshold, max_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 12: Final Model Selection and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Final Evaluation on Test Set ====\n",
      "\n",
      "Using 10 selected features for final evaluation\n",
      "\n",
      "Finding optimal threshold using validation set...\n",
      "Optimal threshold: 0.250\n",
      "Validation ROC-AUC: 0.707\n",
      "Validation F1-score at optimal threshold: 0.502\n",
      "\n",
      "Test Set Performance:\n",
      "Test ROC-AUC: 0.727\n",
      "Test F1-score at optimal threshold: 0.525\n",
      "\n",
      "Classification Report at Optimal Threshold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.86      4673\n",
      "           1       0.50      0.55      0.53      1327\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.68      0.70      0.69      6000\n",
      "weighted avg       0.79      0.78      0.78      6000\n",
      "\n",
      "\n",
      "Analysis complete. Results and visualizations have been saved to the 'results' directory.\n",
      "Test set predictions have been saved to 'results/logistic_regression_test_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# Section 12: Final Model Selection and Evaluation\n",
    "print(\"\\n==== Final Evaluation on Test Set ====\")\n",
    "# Get the best model and its features\n",
    "best_model = best_models[best_model_name]\n",
    "selected_features = None\n",
    "if best_model_name.startswith('Forward Selection'):\n",
    "    selected_features = best_forward_features\n",
    "elif best_model_name.startswith('Backward Selection'):\n",
    "    selected_features = best_backward_features\n",
    "\n",
    "# For the best model, evaluate on both validation and test sets\n",
    "if selected_features is not None:\n",
    "    print(f\"\\nUsing {len(selected_features)} selected features for final evaluation\")\n",
    "    X_val_use = X_val[selected_features]\n",
    "    X_test_use = X_test[selected_features]\n",
    "else:\n",
    "    X_val_use = X_val\n",
    "    X_test_use = X_test\n",
    "\n",
    "# Fit the model on training data\n",
    "best_model.fit(X_train if selected_features is None else X_train[selected_features], y_train)\n",
    "\n",
    "# Get predictions on validation set\n",
    "val_pred_proba = best_model.predict_proba(X_val_use)[:, 1]\n",
    "val_roc_auc = roc_auc_score(y_val, val_pred_proba)\n",
    "\n",
    "# Find optimal threshold using validation set\n",
    "print(\"\\nFinding optimal threshold using validation set...\")\n",
    "optimal_threshold, val_max_f1 = find_optimal_threshold(y_val, val_pred_proba)\n",
    "print(f\"Optimal threshold: {optimal_threshold:.3f}\")\n",
    "print(f\"Validation ROC-AUC: {val_roc_auc:.3f}\")\n",
    "print(f\"Validation F1-score at optimal threshold: {val_max_f1:.3f}\")\n",
    "\n",
    "# Apply to test set\n",
    "test_pred_proba = best_model.predict_proba(X_test_use)[:, 1]\n",
    "test_pred = (test_pred_proba >= optimal_threshold).astype(int)\n",
    "test_roc_auc = roc_auc_score(y_test, test_pred_proba)\n",
    "test_f1 = f1_score(y_test, test_pred)\n",
    "\n",
    "# Save test set predictions and actual values\n",
    "test_results = pd.DataFrame({\n",
    "    'actual': y_test,\n",
    "    'predicted': test_pred,\n",
    "    'probability': test_pred_proba\n",
    "})\n",
    "test_results.to_csv(os.path.join(results_dir, 'logistic_regression_test_predictions.csv'), index=False)\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(f\"Test ROC-AUC: {test_roc_auc:.3f}\")\n",
    "print(f\"Test F1-score at optimal threshold: {test_f1:.3f}\")\n",
    "\n",
    "print(\"\\nClassification Report at Optimal Threshold:\")\n",
    "print(classification_report(y_test, test_pred))\n",
    "\n",
    "# Save the best model and optimal threshold\n",
    "joblib.dump({\n",
    "    'model': best_model,\n",
    "    'optimal_threshold': optimal_threshold,\n",
    "    'selected_features': selected_features\n",
    "}, os.path.join(results_dir, 'best_model.pkl'))\n",
    "\n",
    "print(f\"\\nAnalysis complete. Results and visualizations have been saved to the '{results_dir}' directory.\")\n",
    "print(f\"Test set predictions have been saved to '{results_dir}/logistic_regression_test_predictions.csv'\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
