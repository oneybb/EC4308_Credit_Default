{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1c9b4ae",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "048fd756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Basic Information:\n",
      "Shape of dataset: (30000, 25)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv(\"data/UCI_Credit_Card.csv\")\n",
    "\n",
    "# Basic information about the dataset\n",
    "print(\"\\nBasic Information:\")\n",
    "print(f\"Shape of dataset: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a44b9154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in each column:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   ID                          30000 non-null  int64  \n",
      " 1   LIMIT_BAL                   30000 non-null  float64\n",
      " 2   SEX                         30000 non-null  int64  \n",
      " 3   EDUCATION                   30000 non-null  int64  \n",
      " 4   MARRIAGE                    30000 non-null  int64  \n",
      " 5   AGE                         30000 non-null  int64  \n",
      " 6   PAY_0                       30000 non-null  int64  \n",
      " 7   PAY_2                       30000 non-null  int64  \n",
      " 8   PAY_3                       30000 non-null  int64  \n",
      " 9   PAY_4                       30000 non-null  int64  \n",
      " 10  PAY_5                       30000 non-null  int64  \n",
      " 11  PAY_6                       30000 non-null  int64  \n",
      " 12  BILL_AMT1                   30000 non-null  float64\n",
      " 13  BILL_AMT2                   30000 non-null  float64\n",
      " 14  BILL_AMT3                   30000 non-null  float64\n",
      " 15  BILL_AMT4                   30000 non-null  float64\n",
      " 16  BILL_AMT5                   30000 non-null  float64\n",
      " 17  BILL_AMT6                   30000 non-null  float64\n",
      " 18  PAY_AMT1                    30000 non-null  float64\n",
      " 19  PAY_AMT2                    30000 non-null  float64\n",
      " 20  PAY_AMT3                    30000 non-null  float64\n",
      " 21  PAY_AMT4                    30000 non-null  float64\n",
      " 22  PAY_AMT5                    30000 non-null  float64\n",
      " 23  PAY_AMT6                    30000 non-null  float64\n",
      " 24  default.payment.next.month  30000 non-null  int64  \n",
      "dtypes: float64(13), int64(12)\n",
      "memory usage: 5.7 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b1f1d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in EDUCATION: [2 1 3 5 4 6 0]\n",
      "Unique values in MARRIAGE: [1 2 3 0]\n",
      "\n",
      "After cleaning:\n",
      "Unique values in EDUCATION: [2 1 3 4]\n",
      "Unique values in MARRIAGE: [1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# Drop ID column (not useful for modeling)\n",
    "credit_data = df.drop('ID', axis=1)\n",
    "\n",
    "# Check education and marriage for unusual values\n",
    "print(\"\\nUnique values in EDUCATION:\", credit_data['EDUCATION'].unique())\n",
    "print(\"Unique values in MARRIAGE:\", credit_data['MARRIAGE'].unique())\n",
    "\n",
    "# Fix education and marriage variables:\n",
    "credit_data['EDUCATION'] = credit_data['EDUCATION'].map(lambda x: 4 if x in [0, 5, 6] else x)\n",
    "credit_data['MARRIAGE'] = credit_data['MARRIAGE'].map(lambda x: 3 if x == 0 else x)\n",
    "\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(\"Unique values in EDUCATION:\", credit_data['EDUCATION'].unique())\n",
    "print(\"Unique values in MARRIAGE:\", credit_data['MARRIAGE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7520d3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (18000, 23)\n",
      "Validation set shape: (6000, 23)\n",
      "Test set shape: (6000, 23)\n"
     ]
    }
   ],
   "source": [
    "# Feature and target variables\n",
    "X = credit_data.drop('default.payment.next.month', axis=1)\n",
    "y = credit_data['default.payment.next.month']\n",
    "\n",
    "# Split data into training, validation and test sets (60%, 20%, 20%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['LIMIT_BAL', 'AGE'] + [col for col in X.columns if col.startswith('BILL_') or col.startswith('PAY_AMT')]\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_val[numerical_cols] = scaler.transform(X_val[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6164d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving preprocessed data to CSV files...\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV files\n",
    "print(\"Saving preprocessed data to CSV files...\")\n",
    "X_train.to_csv(\"data/X_train.csv\", index=False)\n",
    "X_val.to_csv(\"data/X_val.csv\", index=False)\n",
    "X_test.to_csv(\"data/X_test.csv\", index=False)\n",
    "y_train.to_csv(\"data/y_train.csv\", index=False)\n",
    "y_val.to_csv(\"data/y_val.csv\", index=False)\n",
    "y_test.to_csv(\"data/y_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
